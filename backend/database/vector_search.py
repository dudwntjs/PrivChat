import os
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from dotenv import load_dotenv, find_dotenv
from pymongo import MongoClient

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = find_dotenv()  # .env íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
if not dotenv_path:
    raise FileNotFoundError("âŒ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

load_dotenv(dotenv_path)  # .env íŒŒì¼ ë¡œë“œ

# OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

print("âœ… OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ!")

# OpenAI ì„ë² ë”© ì‚¬ìš©
embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")

# FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
def load_vector_store():
    # FAISS ë²¡í„° ì €ì¥ì†Œ ë¶ˆëŸ¬ì˜¤ê¸° (allow dangerous deserialization)
    vectorstore = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)
    return vectorstore

# ì¿¼ë¦¬ ê²€ìƒ‰ í•¨ìˆ˜
def search_query(query, vectorstore, k=5):
    # ì…ë ¥ëœ ì¿¼ë¦¬ë¥¼ ë²¡í„°í™”í•˜ì—¬ ê²€ìƒ‰
    search_results = vectorstore.similarity_search(query, k)
    return search_results

if __name__ == "__main__":
    # FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
    vectorstore = load_vector_store()

    # ê²€ìƒ‰ ì¿¼ë¦¬ ì˜ˆì‹œ
    query = "ë²•ì  ê·¼ê±°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
    
    # ê²€ìƒ‰ ìˆ˜í–‰
    results = search_query(query, vectorstore, k=5)

    print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 5ê°œ):")
    for result in results:
        print(f"- {result.page_content[:300]}...")  # ê²°ê³¼ì˜ ì• 300ì ì¶œë ¥